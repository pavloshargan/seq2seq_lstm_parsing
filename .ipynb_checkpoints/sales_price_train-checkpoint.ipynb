{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pasha/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/pasha/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/pasha/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/pasha/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/pasha/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/pasha/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/pasha/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/pasha/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/pasha/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/pasha/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/pasha/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/pasha/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/pashanator/seq2seq_lstm_parsing\" target=\"_blank\">https://app.wandb.ai/pashanator/seq2seq_lstm_parsing</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/pashanator/seq2seq_lstm_parsing/runs/1nm4b3it\" target=\"_blank\">https://app.wandb.ai/pashanator/seq2seq_lstm_parsing/runs/1nm4b3it</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, TimeDistributed, RepeatVector, Dense, BatchNormalization\n",
    "import numpy as np\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "import random\n",
    "\n",
    "wandb.init()\n",
    "config = wandb.config\n",
    "\n",
    "class CharacterTable(object):\n",
    "    \"\"\"Given a set of characters:\n",
    "    + Encode them to a one hot integer representation\n",
    "    + Decode the one hot integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    \"\"\"\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize character table.\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One hot encode given string C.\n",
    "        # Arguments\n",
    "            num_rows: Number of rows in the returned one hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return ''.join(self.indices_char[x] for x in x)\n",
    "\n",
    "# Parameters for the model and dataset.\n",
    "config.hidden_size = 128\n",
    "config.batch_size = 32\n",
    "\n",
    "maxlen = 25 #input max len\n",
    "output_len = 10 # output max len\n",
    "# All the possible symbols in the input \n",
    "chars = '0123456789+$-,/.ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuwxyv '\n",
    "ctable = CharacterTable(chars)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"sale_prices.csv\")\n",
    "df = df.fillna(0)\n",
    "from sklearn.utils import shuffle\n",
    "df = shuffle(df)\n",
    "\n",
    "\n",
    "raw_prices = df[\"Price on site\"].tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train prices: 287500\n",
      "Total validation prices: 62\n",
      "Vectorization...\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_12 (LSTM)               (None, 128)               100864    \n",
      "_________________________________________________________________\n",
      "repeat_vector_6 (RepeatVecto (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 10, 128)           512       \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 10, 128)           131584    \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 10, 68)            8772      \n",
      "=================================================================\n",
      "Total params: 241,732\n",
      "Trainable params: 241,476\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Train on 287500 samples, validate on 62 samples\n",
      "    32/287500 [..............................] - ETA: 8:05:37 - loss: 4.2143 - acc: 0.0562WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.483168). Check your callbacks.\n",
      "287500/287500 [==============================] - 828s 3ms/sample - loss: 0.2214 - acc: 0.9191 - val_loss: 0.0571 - val_acc: 0.9806\n",
      "Q $409,900                  T 409900     ☑ G 409900    \n",
      "Q $453,600                  T 453600     ☒ G 453000    \n",
      "Q $1,635,000                T 1635000    ☑ G 1635000   \n",
      "Q $1,750,000                T 1750000    ☑ G 1750000   \n",
      "Q $1,650,000                T 1650000    ☑ G 1650000   \n",
      "Q From $386,490             T 386490     ☒ G 886499    \n",
      "Q $154,580                  T 154580     ☒ G 155588    \n",
      "Q $13,625,000               T 13625000   ☒ G 13620000  \n",
      "Q $544,900                  T 544900     ☑ G 544900    \n",
      "Q $145,000                  T 145000     ☑ G 145000    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Train on 287500 samples, validate on 62 samples\n",
      "287500/287500 [==============================] - 831s 3ms/sample - loss: 0.0174 - acc: 0.9941 - val_loss: 0.0095 - val_acc: 0.9984\n",
      "Q $950,000                  T 950000     ☑ G 950000    \n",
      "Q $1,500,000                T 1500000    ☑ G 1500000   \n",
      "Q $1,000,000                T 1000000    ☑ G 1000000   \n",
      "Q $4,999                    T 4999       ☑ G 4999      \n",
      "Q $544,900                  T 544900     ☑ G 544900    \n",
      "Q $79,900                   T 79900      ☑ G 79900     \n",
      "Q $1,689,000+               T 1689000    ☑ G 1689000   \n",
      "Q $4,999                    T 4999       ☑ G 4999      \n",
      "Q $18,262,000               T 18262000   ☑ G 18262000  \n",
      "Q $3,150,000                T 3150000    ☑ G 3150000   \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Train on 287500 samples, validate on 62 samples\n",
      "287500/287500 [==============================] - 819s 3ms/sample - loss: 0.0042 - acc: 0.9987 - val_loss: 0.0027 - val_acc: 0.9984\n",
      "Q $575,000                  T 575000     ☑ G 575000    \n",
      "Q $1,450,000                T 1450000    ☑ G 1450000   \n",
      "Q $990,000                  T 990000     ☑ G 990000    \n",
      "Q $375,000                  T 375000     ☑ G 375000    \n",
      "Q $595,000                  T 595000     ☑ G 595000    \n",
      "Q $3,999,999                T 3999999    ☑ G 3999999   \n",
      "Q $1,495,900+               T 1495900    ☑ G 1495900   \n",
      "Q $1,895,000                T 1895000    ☑ G 1895000   \n",
      "Q $424,900                  T 424900     ☑ G 424900    \n",
      "Q $100,000                  T 100000     ☑ G 100000    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Train on 287500 samples, validate on 62 samples\n",
      "287500/287500 [==============================] - 972s 3ms/sample - loss: 0.0019 - acc: 0.9994 - val_loss: 0.0075 - val_acc: 0.9984\n",
      "Q $250,000                  T 250000     ☑ G 250000    \n",
      "Q $749,000                  T 749000     ☑ G 749000    \n",
      "Q $1,199,900                T 1199900    ☑ G 1199900   \n",
      "Q $199,950                  T 199950     ☑ G 199950    \n",
      "Q $4,875,000                T 4875000    ☑ G 4875000   \n",
      "Q $7,500,000                T 7500000    ☑ G 7500000   \n",
      "Q $350,000                  T 350000     ☑ G 350000    \n",
      "Q $950,000                  T 950000     ☑ G 950000    \n",
      "Q $145,000                  T 145000     ☑ G 145000    \n",
      "Q $1,150,000                T 1150000    ☑ G 1150000   \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Train on 287500 samples, validate on 62 samples\n",
      "287500/287500 [==============================] - 894s 3ms/sample - loss: 0.0011 - acc: 0.9997 - val_loss: 2.9819e-04 - val_acc: 1.0000\n",
      "Q $1,895,000                T 1895000    ☑ G 1895000   \n",
      "Q $1,699,999                T 1699999    ☑ G 1699999   \n",
      "Q $945,000                  T 945000     ☑ G 945000    \n",
      "Q $232,000                  T 232000     ☑ G 232000    \n",
      "Q $4,999                    T 4999       ☑ G 4999      \n",
      "Q $595,000                  T 595000     ☑ G 595000    \n",
      "Q $749,000                  T 749000     ☑ G 749000    \n",
      "Q $990,000                  T 990000     ☑ G 990000    \n",
      "Q $1,825,000                T 1825000    ☑ G 1825000   \n",
      "Q $135,000                  T 135000     ☑ G 135000    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Train on 287500 samples, validate on 62 samples\n",
      "110176/287500 [==========>...................] - ETA: 8:33 - loss: 0.0010 - acc: 0.9997"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-eaf8df46d85d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     82\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m               validation_data=(x_val, y_val),callbacks=[WandbCallback()])\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0;31m# Select 10 samples from the validation set at random so we can visualize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m# errors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/wandb/keras/__init__.py\u001b[0m in \u001b[0;36mnew_arrays\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mval_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_targets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnew_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#MIN_PRICE MODEL\n",
    "  \n",
    "int_min_price = [int(price) for price in df[\"Min price\"]]\n",
    "  \n",
    "split_at = len(int_min_price) - len(int_min_price) // 10\n",
    "\n",
    "#train data\n",
    "raw_prices_train = []\n",
    "parced_prices_train = []\n",
    "#training data augmentation  \n",
    "for i in range(500):  #augmentation x500 times (from ~500 to 250000 ~datapoints)\n",
    "    for idx in range(split_at):\n",
    "        raw_price = str(raw_prices[idx])\n",
    "        parsed_price = str(int_min_price[idx])\n",
    "        for i in range(len(parsed_price)):\n",
    "            to_replace = parsed_price[i]\n",
    "            replace_with = to_replace\n",
    "            if i == 0: # to do not make first digit as zero\n",
    "                if str(int_min_price[idx])[0] != '0':\n",
    "                    replace_with = str(random.randint(1,9))\n",
    "            else:\n",
    "                replace_with = str(random.randint(0,9))\n",
    "            parsed_price = parsed_price.replace(to_replace,replace_with)\n",
    "            raw_price = raw_price.replace(to_replace,replace_with)\n",
    "\n",
    "        parsed_price+=' '*(output_len - len(str(int_min_price[idx])))\n",
    "        parced_prices_train.append(parsed_price)\n",
    "        raw_prices_train.append(raw_price)\n",
    "         \n",
    "        \n",
    "#val data\n",
    "raw_prices_val = []\n",
    "parced_prices_val = []\n",
    "for idx in range(split_at,len(raw_prices)-1):\n",
    "    raw_price = str(raw_prices[idx])\n",
    "    parsed_price = str(int_min_price[idx])\n",
    "\n",
    "    parsed_price+=' '*(output_len - len(str(int_min_price[idx])))\n",
    "    parced_prices_val.append(parsed_price)\n",
    "    raw_prices_val.append(raw_price)\n",
    "     \n",
    "        \n",
    "        \n",
    "print('Total train prices:', len(raw_prices_train))\n",
    "print('Total validation prices:', len(raw_prices_val))\n",
    "\n",
    "print('Vectorization...')\n",
    "x_train = np.zeros((len(raw_prices_train), maxlen, len(chars)), dtype=np.bool)\n",
    "y_train = np.zeros((len(parced_prices_train), output_len, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(raw_prices_train):\n",
    "    x_train[i] = ctable.encode(str(sentence), maxlen)\n",
    "for i, sentence in enumerate(parced_prices_train):\n",
    "    y_train[i] = ctable.encode(str(sentence), output_len)\n",
    "    \n",
    "x_val = np.zeros((len(raw_prices_val), maxlen, len(chars)), dtype=np.bool)\n",
    "y_val = np.zeros((len(parced_prices_val), output_len, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(raw_prices_val):\n",
    "    x_val[i] = ctable.encode(str(sentence), maxlen)\n",
    "for i, sentence in enumerate(parced_prices_val):\n",
    "    y_val[i] = ctable.encode(str(sentence), output_len)\n",
    "\n",
    "min_price_model = Sequential()\n",
    "min_price_model.add(LSTM(config.hidden_size, input_shape=(maxlen, len(chars))))\n",
    "min_price_model.add(RepeatVector(output_len))\n",
    "\n",
    "min_price_model.add(BatchNormalization())\n",
    "\n",
    "min_price_model.add(LSTM(config.hidden_size, return_sequences=True))\n",
    "min_price_model.add(TimeDistributed(Dense(len(chars), activation='softmax')))\n",
    "min_price_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "min_price_model.summary()\n",
    "\n",
    "# Train the model each generation and show predictions against the validation\n",
    "# dataset.\n",
    "for iteration in range(1, 50):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    min_price_model.fit(x_train, y_train,\n",
    "              batch_size=config.batch_size,\n",
    "              epochs=1,\n",
    "              validation_data=(x_val, y_val),callbacks=[WandbCallback()])\n",
    "    # Select 10 samples from the validation set at random so we can visualize\n",
    "    # errors.\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = min_price_model.predict_classes(rowx, verbose=0)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        print('Q', q, end=' ')\n",
    "        print('T', correct, end=' ')\n",
    "        if correct == guess:\n",
    "            print('☑', end=' ')\n",
    "        else:\n",
    "            print('☒', end=' ')\n",
    "        print('G',guess, end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min price prediction ----------------------------------------\n",
      "Q $145,000                  T 145000     ☑ G 145000    \n",
      "Q $300,000                  T 300000     ☑ G 300000    \n",
      "Q $135,000                  T 135000     ☑ G 135000    \n",
      "Q $424,900                  T 424900     ☑ G 424900    \n",
      "Q $154,580                  T 154580     ☑ G 154580    \n",
      "Q $89,900                   T 89900      ☑ G 89900     \n",
      "Q $1,150,000                T 1150000    ☑ G 1150000   \n",
      "Q $240,000                  T 240000     ☑ G 240000    \n",
      "Q $375,000                  T 375000     ☑ G 375000    \n",
      "Q $3,150,000                T 3150000    ☑ G 3150000   \n",
      "Q $5,200,000                T 5200000    ☑ G 5200000   \n",
      "Q $1,895,000                T 1895000    ☑ G 1895000   \n",
      "Q $80,000                   T 80000      ☑ G 80000     \n",
      "Q $240,000                  T 240000     ☑ G 240000    \n",
      "Q $79,900                   T 79900      ☑ G 79900     \n",
      "Q $544,900                  T 544900     ☑ G 544900    \n",
      "Q From $386,490             T 386490     ☑ G 386490    \n",
      "Q $1,750,000                T 1750000    ☑ G 1750000   \n",
      "Q $350,000                  T 350000     ☑ G 350000    \n",
      "Q $232,000                  T 232000     ☑ G 232000    \n",
      "Q $409,900                  T 409900     ☑ G 409900    \n",
      "Q $250,000                  T 250000     ☑ G 250000    \n",
      "Q $825,000                  T 825000     ☑ G 825000    \n",
      "Q $1,650,000                T 1650000    ☑ G 1650000   \n",
      "Q $18,262,000               T 18262000   ☑ G 18262000  \n",
      "Q $2,595,000                T 2595000    ☑ G 2595000   \n",
      "Q $1,450,000                T 1450000    ☑ G 1450000   \n",
      "Q $4,875,000                T 4875000    ☑ G 4875000   \n",
      "Q $1,750,000                T 1750000    ☑ G 1750000   \n",
      "Q $1,500,000                T 1500000    ☑ G 1500000   \n",
      "Q $990,000                  T 990000     ☑ G 990000    \n",
      "Q $1,635,000                T 1635000    ☑ G 1635000   \n",
      "Q $279,900                  T 279900     ☑ G 279900    \n",
      "Q $179,999                  T 179999     ☑ G 179999    \n",
      "Q $3,999,999                T 3999999    ☑ G 3999999   \n",
      "Q $1,300,000                T 1300000    ☑ G 1300000   \n",
      "Q $945,000                  T 945000     ☑ G 945000    \n",
      "Q $7,500,000                T 7500000    ☑ G 7500000   \n",
      "Q $1,825,000                T 1825000    ☑ G 1825000   \n",
      "Q $1,000,000                T 1000000    ☑ G 1000000   \n",
      "Q Price Unavailable         T 0          ☑ G 0         \n",
      "Q $950,000                  T 950000     ☑ G 950000    \n",
      "Q $1,199,900                T 1199900    ☑ G 1199900   \n",
      "Q $525,990+                 T 525990     ☑ G 525990    \n",
      "Q $2,750,000                T 2750000    ☑ G 2750000   \n",
      "Q $1,699,999                T 1699999    ☑ G 1699999   \n",
      "Q $749,000                  T 749000     ☑ G 749000    \n",
      "Q $453,600                  T 453600     ☑ G 453600    \n",
      "Q $100,000                  T 100000     ☑ G 100000    \n",
      "Q $13,500,000               T 13500000   ☑ G 13500000  \n",
      "Q $230,000                  T 230000     ☑ G 230000    \n",
      "Q $4,999                    T 4999       ☑ G 4999      \n",
      "Q $1,495,900+               T 1495900    ☑ G 1495900   \n",
      "Q $628,800                  T 628800     ☑ G 628800    \n",
      "Q $899,950                  T 899950     ☑ G 899950    \n",
      "Q $13,625,000               T 13625000   ☑ G 13625000  \n",
      "Q $1,689,000+               T 1689000    ☑ G 1689000   \n",
      "Q $199,950                  T 199950     ☑ G 199950    \n",
      "Q $979,999                  T 979999     ☑ G 979999    \n",
      "Q $575,000                  T 575000     ☑ G 575000    \n",
      "Q $595,000                  T 595000     ☑ G 595000    \n",
      "Q $2,695,000                T 2695000    ☑ G 2695000   \n"
     ]
    }
   ],
   "source": [
    "print('Min price prediction ----------------------------------------')\n",
    "for ind in range(len(x_val)):\n",
    "    rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "    preds = min_price_model.predict_classes(rowx, verbose=0)\n",
    "    q = ctable.decode(rowx[0])\n",
    "    correct = ctable.decode(rowy[0])\n",
    "    guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "    print('Q', q, end=' ')\n",
    "    print('T', correct, end=' ')\n",
    "    if correct == guess:\n",
    "        print('☑', end=' ')\n",
    "    else:\n",
    "        print('☒', end=' ')\n",
    "    print('G',guess, end='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train prices: 287500\n",
      "Total validation prices: 62\n",
      "Vectorization...\n",
      "WARNING:tensorflow:From /home/pasha/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 128)               100864    \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 10, 128)           512       \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 10, 128)           131584    \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 10, 68)            8772      \n",
      "=================================================================\n",
      "Total params: 241,732\n",
      "Trainable params: 241,476\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 0\n",
      "Train on 287500 samples, validate on 62 samples\n",
      "WARNING:tensorflow:From /home/pasha/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "287500/287500 [==============================] - 655s 2ms/sample - loss: 0.2421 - acc: 0.9109 - val_loss: 0.1608 - val_acc: 0.9371\n",
      "Q $2,500,000                T 2500000    ☑ G 2500000   \n",
      "Q $529,999                  T 529999     ☑ G 529999    \n",
      "Q $799,000                  T 799000     ☑ G 799000    \n",
      "Q $2,100,000                T 2100000    ☑ G 2100000   \n",
      "Q $979,999                  T 979999     ☒ G 999999    \n",
      "Q $104,900                  T 104900     ☑ G 104900    \n",
      "Q $525,000                  T 525000     ☒ G 555000    \n",
      "Q 0                         T 0          ☑ G 0         \n",
      "Q $595,000                  T 595000     ☒ G 555000    \n",
      "Q $210,000                  T 210000     ☑ G 210000    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Train on 287500 samples, validate on 62 samples\n",
      "287500/287500 [==============================] - 651s 2ms/sample - loss: 0.0273 - acc: 0.9907 - val_loss: 0.0282 - val_acc: 0.9855\n",
      "Q $407,898                  T 407898     ☒ G 407888    \n",
      "Q $11,300,000               T 11300000   ☑ G 11300000  \n",
      "Q $689,000                  T 689000     ☑ G 689000    \n",
      "Q $150,000                  T 150000     ☑ G 150000    \n",
      "Q $11,300,000               T 11300000   ☑ G 11300000  \n",
      "Q $364,999                  T 364999     ☑ G 364999    \n",
      "Q $15,000                   T 15000      ☑ G 15000     \n",
      "Q $407,898                  T 407898     ☒ G 407888    \n",
      "Q $115,000                  T 115000     ☑ G 115000    \n",
      "Q $979,999                  T 979999     ☑ G 979999    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Train on 287500 samples, validate on 62 samples\n",
      "287500/287500 [==============================] - 655s 2ms/sample - loss: 0.0062 - acc: 0.9981 - val_loss: 0.0043 - val_acc: 0.9984\n",
      "Q $2,500,000                T 2500000    ☑ G 2500000   \n",
      "Q Est. $73,822              T 73822      ☑ G 73822     \n",
      "Q $210,000                  T 210000     ☑ G 210000    \n",
      "Q $979,999                  T 979999     ☑ G 979999    \n",
      "Q $799,000                  T 799000     ☑ G 799000    \n",
      "Q $189,000                  T 189000     ☑ G 189000    \n",
      "Q $495,000                  T 495000     ☑ G 495000    \n",
      "Q $5,950,000                T 5950000    ☑ G 5950000   \n",
      "Q $4,999                    T 4999       ☑ G 4999      \n",
      "Q $825,000                  T 825000     ☑ G 825000    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Train on 287500 samples, validate on 62 samples\n",
      "287500/287500 [==============================] - 679s 2ms/sample - loss: 0.0025 - acc: 0.9992 - val_loss: 5.0247e-04 - val_acc: 1.0000\n",
      "Q $104,900                  T 104900     ☑ G 104900    \n",
      "Q $108,900                  T 108900     ☑ G 108900    \n",
      "Q $999,000                  T 999000     ☑ G 999000    \n",
      "Q $60,000 - $388,500        T 388500     ☑ G 388500    \n",
      "Q $99,000                   T 99000      ☑ G 99000     \n",
      "Q 0                         T 0          ☑ G 0         \n",
      "Q $65,000                   T 65000      ☑ G 65000     \n",
      "Q $5,950,000                T 5950000    ☑ G 5950000   \n",
      "Q $525,000                  T 525000     ☑ G 525000    \n",
      "Q $1,495,000                T 1495000    ☑ G 1495000   \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Train on 287500 samples, validate on 62 samples\n",
      "287500/287500 [==============================] - 661s 2ms/sample - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Q $1,499,000                T 1499000    ☑ G 1499000   \n",
      "Q $189,000                  T 189000     ☑ G 189000    \n",
      "Q $495,000                  T 495000     ☑ G 495000    \n",
      "Q $23,000                   T 23000      ☑ G 23000     \n",
      "Q $1,500,000                T 1500000    ☑ G 1500000   \n",
      "Q $65,000                   T 65000      ☑ G 65000     \n",
      "Q $4,999                    T 4999       ☑ G 4999      \n",
      "Q $1,120,000                T 1120000    ☑ G 1120000   \n",
      "Q $595,000                  T 595000     ☑ G 595000    \n",
      "Q $133,999                  T 133999     ☑ G 133999    \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Train on 287500 samples, validate on 62 samples\n",
      " 23456/287500 [=>............................] - ETA: 10:24 - loss: 0.0010 - acc: 0.9997"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c2335db87d3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     78\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m               validation_data=(x_val, y_val),callbacks=[WandbCallback()])\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;31m# Select 10 samples from the validation set at random so we can visualize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;31m# errors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/wandb/keras/__init__.py\u001b[0m in \u001b[0;36mnew_arrays\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mval_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_targets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnew_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#MAX_PRICE MODEL\n",
    "int_max_price = [int(price) for price in df[\"Max price\"]]\n",
    " \n",
    "split_at = len(int_max_price) - len(int_max_price) // 10\n",
    "\n",
    "#train data\n",
    "raw_prices_train = []\n",
    "parced_prices_train = []\n",
    "for i in range(500):  #augmentation x1000 times (from ~500 to 250000 ~datapoints)\n",
    "    for idx in range(split_at):\n",
    "        raw_price = str(raw_prices[idx])\n",
    "        parsed_price = str(int_max_price[idx])\n",
    "        for i in range(len(parsed_price)):\n",
    "            to_replace = parsed_price[i]\n",
    "            replace_with = to_replace\n",
    "            if i == 0: # to do not make first digit as zero\n",
    "                if str(int_max_price[idx])[0] != '0':\n",
    "                    replace_with = str(random.randint(1,9))\n",
    "            else:\n",
    "                replace_with = str(random.randint(0,9))\n",
    "            parsed_price = parsed_price.replace(to_replace,replace_with)\n",
    "            raw_price = raw_price.replace(to_replace,replace_with)\n",
    "\n",
    "        parsed_price+=' '*(output_len - len(str(int_max_price[idx])))\n",
    "        parced_prices_train.append(parsed_price)\n",
    "        raw_prices_train.append(raw_price)\n",
    "        \n",
    "#val data\n",
    "raw_prices_val = []\n",
    "parced_prices_val = []\n",
    "for idx in range(split_at,len(raw_prices)-1):\n",
    "    raw_price = str(raw_prices[idx])\n",
    "    parsed_price = str(int_max_price[idx])\n",
    "\n",
    "    parsed_price+=' '*(output_len - len(str(int_max_price[idx])))\n",
    "    parced_prices_val.append(parsed_price)\n",
    "    raw_prices_val.append(raw_price)\n",
    "        \n",
    "        \n",
    "print('Total train prices:', len(raw_prices_train))\n",
    "print('Total validation prices:', len(raw_prices_val))\n",
    "\n",
    "print('Vectorization...')\n",
    "x_train = np.zeros((len(raw_prices_train), maxlen, len(chars)), dtype=np.bool)\n",
    "y_train = np.zeros((len(parced_prices_train), output_len, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(raw_prices_train):\n",
    "    x_train[i] = ctable.encode(str(sentence), maxlen)\n",
    "for i, sentence in enumerate(parced_prices_train):\n",
    "    y_train[i] = ctable.encode(str(sentence), output_len)\n",
    "    \n",
    "x_val = np.zeros((len(raw_prices_val), maxlen, len(chars)), dtype=np.bool)\n",
    "y_val = np.zeros((len(parced_prices_val), output_len, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(raw_prices_val):\n",
    "    x_val[i] = ctable.encode(str(sentence), maxlen)\n",
    "for i, sentence in enumerate(parced_prices_val):\n",
    "    y_val[i] = ctable.encode(str(sentence), output_len)\n",
    "\n",
    "max_price_model = Sequential()\n",
    "max_price_model.add(LSTM(config.hidden_size, input_shape=(maxlen, len(chars))))\n",
    "max_price_model.add(RepeatVector(output_len))\n",
    "\n",
    "max_price_model.add(BatchNormalization())\n",
    "\n",
    "max_price_model.add(LSTM(config.hidden_size, return_sequences=True))\n",
    "max_price_model.add(TimeDistributed(Dense(len(chars), activation='softmax')))\n",
    "max_price_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "max_price_model.summary()\n",
    "\n",
    "# Train the model each generation and show predictions against the validation\n",
    "# dataset.\n",
    "for iteration in range(50):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    max_price_model.fit(x_train, y_train,\n",
    "              batch_size=config.batch_size,\n",
    "              epochs=1,\n",
    "              validation_data=(x_val, y_val),callbacks=[WandbCallback()])\n",
    "    # Select 10 samples from the validation set at random so we can visualize\n",
    "    # errors.\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = max_price_model.predict_classes(rowx, verbose=0)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        print('Q', q, end=' ')\n",
    "        print('T', correct, end=' ')\n",
    "        if correct == guess:\n",
    "            print('☑', end=' ')\n",
    "        else:\n",
    "            print('☒', end=' ')\n",
    "        print('G',guess, end='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Max price prediction ----------------------------------------')\n",
    "for ind in range(len(x_val)):\n",
    "    rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "    preds = max_price_model.predict_classes(rowx, verbose=0)\n",
    "    q = ctable.decode(rowx[0])\n",
    "    correct = ctable.decode(rowy[0])\n",
    "    guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "    print('Q', q, end=' ')\n",
    "    print('T', correct, end=' ')\n",
    "    if correct == guess:\n",
    "        print('☑', end=' ')\n",
    "    else:\n",
    "        print('☒', end=' ')\n",
    "    print('G',guess, end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
