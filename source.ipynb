{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/pashanator/seq2seq_lstm_parsing\" target=\"_blank\">https://app.wandb.ai/pashanator/seq2seq_lstm_parsing</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/pashanator/seq2seq_lstm_parsing/runs/2ru5eo3a\" target=\"_blank\">https://app.wandb.ai/pashanator/seq2seq_lstm_parsing/runs/2ru5eo3a</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train prices: 575000\n",
      "Total validation prices: 62\n",
      "Vectorization...\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 256)               332800    \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 10, 256)           1024      \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 10, 256)           525312    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 10, 68)            17476     \n",
      "=================================================================\n",
      "Total params: 876,612\n",
      "Trainable params: 876,100\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Train on 575000 samples, validate on 62 samples\n",
      " 91840/575000 [===>..........................] - ETA: 26:27 - loss: 0.3868 - acc: 0.8573"
     ]
    }
   ],
   "source": [
    "# adapted from https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html\n",
    "# https://www.youtube.com/watch?v=MqugtGD605k\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, TimeDistributed, RepeatVector, Dense, BatchNormalization\n",
    "import numpy as np\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "import random\n",
    "\n",
    "wandb.init()\n",
    "config = wandb.config\n",
    "\n",
    "class CharacterTable(object):\n",
    "    \"\"\"Given a set of characters:\n",
    "    + Encode them to a one hot integer representation\n",
    "    + Decode the one hot integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    \"\"\"\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize character table.\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One hot encode given string C.\n",
    "        # Arguments\n",
    "            num_rows: Number of rows in the returned one hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return ''.join(self.indices_char[x] for x in x)\n",
    "\n",
    "# Parameters for the model and dataset.\n",
    "config.hidden_size = 256\n",
    "config.batch_size = 32\n",
    "\n",
    "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
    "# int is DIGITS.\n",
    "maxlen = 25\n",
    "output_len = 10\n",
    "# All the numbers, plus sign and space for padding.\n",
    "chars = '0123456789+$-,/.ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuwxyv '\n",
    "ctable = CharacterTable(chars)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"sale_prices.csv\")\n",
    "df = df.fillna(0)\n",
    "from sklearn.utils import shuffle\n",
    "df = shuffle(df)\n",
    "\n",
    "\n",
    "raw_prices = df[\"Price on site\"].tolist()\n",
    "parced_prices = []\n",
    "\n",
    "int_min_price = [int(price) for price in df[\"Min price\"]]\n",
    "int_max_price = [int(price) for price in df[\"Max price\"]]\n",
    "\n",
    "# for idx in range(len(int_min_price)):\n",
    "#     toappend = str(int_min_price[idx])\n",
    "#     toappend+=' '*(output_len - len(str(int_min_price[idx])))\n",
    "#     parced_prices.append(toappend)\n",
    "    \n",
    "#augmentation (acc: 0.9878)\n",
    "# for i in range(4):\n",
    "#     for idx in range(len(int_min_price)):\n",
    "#         raw_price = str(raw_prices[idx])\n",
    "#         parsed_price = str(int_min_price[idx])\n",
    "#         num_of_replacements = random.randint(1,5)\n",
    "#         for i in range(num_of_replacements):\n",
    "#             to_replace = str(random.randint(1,9))\n",
    "#             replace_with = str(random.randint(1,9))\n",
    "#             parsed_price.replace(to_replace,replace_with)\n",
    "#             raw_price.replace(to_replace,replace_with)\n",
    "\n",
    "#         parsed_price+=' '*(output_len - len(str(int_min_price[idx])))\n",
    "#         parced_prices.append(parsed_price)\n",
    "#         raw_prices.append(raw_price)\n",
    "\n",
    "#augmentation v2\n",
    "\n",
    "split_at = len(int_min_price) - len(int_min_price) // 10\n",
    "\n",
    "#train data\n",
    "raw_prices_train = []\n",
    "parced_prices_train = []\n",
    "\n",
    "for i in range(1000):  #augmentation x100 times (from ~500 to 500000 ~datapoints)\n",
    "    for idx in range(split_at):\n",
    "        raw_price = str(raw_prices[idx])\n",
    "        parsed_price = str(int_min_price[idx])\n",
    "        for i in range(len(parsed_price)):\n",
    "            to_replace = parsed_price[i]\n",
    "            if i == 0: # to do not make first digit as zero\n",
    "                replace_with = str(random.randint(1,9))\n",
    "            else:\n",
    "                replace_with = str(random.randint(0,9))\n",
    "            parsed_price = parsed_price.replace(to_replace,replace_with)\n",
    "            raw_price = raw_price.replace(to_replace,replace_with)\n",
    "\n",
    "        parsed_price+=' '*(output_len - len(str(int_min_price[idx])))\n",
    "        parced_prices_train.append(parsed_price)\n",
    "        raw_prices_train.append(raw_price)\n",
    "        \n",
    "#val data\n",
    "raw_prices_val = []\n",
    "parced_prices_val = []\n",
    "for index in range(split_at,len(raw_prices)-1):\n",
    "    raw_price = str(raw_prices[index])\n",
    "    parsed_price = str(int_min_price[index])\n",
    "    for i in range(len(parsed_price)):\n",
    "        to_replace = parsed_price[i]\n",
    "        if i == 0: # to do not make first digit as zero\n",
    "            replace_with = str(random.randint(1,9))\n",
    "        else:\n",
    "            replace_with = str(random.randint(0,9))\n",
    "        parsed_price = parsed_price.replace(to_replace,replace_with)\n",
    "        raw_price = raw_price.replace(to_replace,replace_with)\n",
    "\n",
    "    parsed_price+=' '*(output_len - len(str(int_min_price[index])))\n",
    "    parced_prices_val.append(parsed_price)\n",
    "    raw_prices_val.append(raw_price)\n",
    "        \n",
    "        \n",
    "print('Total train prices:', len(raw_prices_train))\n",
    "print('Total validation prices:', len(raw_prices_val))\n",
    "\n",
    "print('Vectorization...')\n",
    "x_train = np.zeros((len(raw_prices_train), maxlen, len(chars)), dtype=np.bool)\n",
    "y_train = np.zeros((len(parced_prices_train), output_len, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(raw_prices_train):\n",
    "    x_train[i] = ctable.encode(str(sentence), maxlen)\n",
    "for i, sentence in enumerate(parced_prices_train):\n",
    "    y_train[i] = ctable.encode(str(sentence), output_len)\n",
    "    \n",
    "x_val = np.zeros((len(raw_prices_val), maxlen, len(chars)), dtype=np.bool)\n",
    "y_val = np.zeros((len(parced_prices_val), output_len, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(raw_prices_val):\n",
    "    x_val[i] = ctable.encode(str(sentence), maxlen)\n",
    "for i, sentence in enumerate(parced_prices_val):\n",
    "    y_val[i] = ctable.encode(str(sentence), output_len)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(config.hidden_size, input_shape=(maxlen, len(chars))))\n",
    "model.add(RepeatVector(output_len))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(config.hidden_size, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(len(chars), activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Train the model each generation and show predictions against the validation\n",
    "# dataset.\n",
    "for iteration in range(1, 200):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=config.batch_size,\n",
    "              epochs=1,\n",
    "              validation_data=(x_val, y_val),callbacks=[WandbCallback()])\n",
    "    # Select 10 samples from the validation set at random so we can visualize\n",
    "    # errors.\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = model.predict_classes(rowx, verbose=0)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        print('Q', q, end=' ')\n",
    "        print('T', correct, end=' ')\n",
    "        if correct == guess:\n",
    "            print('☑', end=' ')\n",
    "        else:\n",
    "            print('☒', end=' ')\n",
    "        print('G',guess, end='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
